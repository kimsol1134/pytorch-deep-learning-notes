{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 [NLP 입문] -NLP Basics\n",
    "### 09-01 Tokenization\n",
    "#### 1. Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/solkim/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화 중 생기는 선택의 순간\n",
    "# Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\n",
    "# Don't , Jone's 토큰화 하는 방법 다양\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "# word_tokenize\n",
    "print(\n",
    "    \"단어 토큰화1 :\",\n",
    "    word_tokenize(\n",
    "        \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
    "    ),\n",
    ")\n",
    "#'Do', \"n't\", 'Jone', \"'s\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"단어 토큰화2 :\",\n",
    "    WordPunctTokenizer().tokenize(\n",
    "        \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
    "    ),\n",
    ")\n",
    "#'Don', \"'\", 't','Jone', \"'\", 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"단어 토큰화3 :\",\n",
    "    text_to_word_sequence(\n",
    "        \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
    "    ),\n",
    ")\n",
    "# \"don't\", \"jone's\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화에서 고려해야할 사항\n",
    "1. 구두점, 특수문자 단순 제외해서는 안됨\n",
    "    1. 마침표(.)도 문장의 경계를 알 수 있음\n",
    "    2. 단어 자체에 구두점 있는 경우도 있음 Ph.D, $45.55\n",
    "2. 줄임말\n",
    "    1. we're -> re는 접어(clitic)\n",
    "3. 단어 내에 띄어쓰기가 있는 경우\n",
    "    1. New York 하나의 단어\n",
    "    2. rock 'n' roll\n",
    "4. 표준 토큰화 예제(Penn Treebank Tokenization)\n",
    "    1. 하이푼으로 구성된 단어는 하나로 유지\n",
    "    2. doesn't 와 같이 아포스트로피로 '접어'가 함꼐하는 단어는 분리해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
    "print(\"트리뱅크 워드토크나이저 :\", tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 토큰화(Sentence Tokenization)\n",
    "1. Corpus 내에서 sentence 단위로 구분하는 작업\n",
    "2. Sentence segmentation 이라고도 함\n",
    "3. 마침표(.)는 문장 중간에 들어가는 경우 많다. ex) aaa@gmail.com으로 결과보내줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 토큰화1 : ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
    "print(\"문장 토큰화1 :\", sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
     ]
    }
   ],
   "source": [
    "text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
    "print(\"문장 토큰화2 :\", sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KSS(Korean Sentence Splitter)\n",
    "import kss\n",
    "\n",
    "text = \"딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?\"\n",
    "print(\"한국어 문장 토큰화 :\", kss.split_sentences(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 토큰화의 어려움\n",
    "1. 영어는 New York 같은 합성어, he's 같은 줄임말 정도만 예외 처리후 띄어쓰기 기준으로 토큰화해도 단어 토큰화 잘 됨\n",
    "2. 한국어에서 띄어쓰기 단위는 '어절' 어절은 단어와 같지 않다.\n",
    "3. 한국어는 교착어다\n",
    "4. 교착어는 조사,어미를 붙여서 쓰는 말이다.\n",
    "\n",
    "### 한국어(교착어) 특성\n",
    "1. 그 라는 단어에 그가, 그에게, 그를, 그와 등등 다양한 조사가 붙는다.\n",
    "2. 같은 단어인데 다른 조사가 붙어서 다른 단어로 인식이 된다.\n",
    "3. 형태소(morpheme) : 뜻을 가진 가장 작은 말의 단위\n",
    "    1. 자립 형태소 : 그 자체로 단어가 되는 형태소 \n",
    "        - 체언(명사,대명사,수사), 수식언(관형사,부사), 감탄사\n",
    "    2. 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소\n",
    "        - 접사, 어미, 조사, 어간\n",
    "4. 영어보다 띄어쓰기가 잘 지켜지지 않는다.\n",
    "    - 띄어쓰기를 재대로 하지 않아도 이해가 되는 경우가 많기 때문\n",
    "    - Tobeornottobethaisthequestion\n",
    "    - 제가이렇게띄어씍를전혀하지않고글을썻다고하더라도글을이해할수있습니다.\n",
    "5. 품사 태깅(Part-of-speech tagging)\n",
    "    - fly : 동사로는 '날다', 명사로는'파리'\n",
    "    - 못 : 부사로는 '할수없다', 명사로는 '망치등을 사용해 목재 따위를 고정하는 물건'\n",
    "    - 단어 토큰화 과정에서 각 단어가 어떤 품사로 쓰였는지를 구분해 놓기도 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/solkim/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화 : ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n",
      "품사 태깅 : [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
    "tokenized_sentence = word_tokenize(text)\n",
    "\n",
    "print(\"단어 토큰화 :\", tokenized_sentence)\n",
    "print(\"품사 태깅 :\", pos_tag(tokenized_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: A restricted method in java.lang.System has been called\n",
      "WARNING: java.lang.System::load has been called by org.jpype.JPypeContext in an unnamed module (file:/Users/solkim/Desktop/projects/my_python_project/DL_pytorch/.venv/lib/python3.11/site-packages/org.jpype.jar)\n",
      "WARNING: Use --enable-native-access=ALL-UNNAMED to avoid a warning for callers in this module\n",
      "WARNING: Restricted methods will be blocked in a future release unless native access is enabled\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKT 형태소 분석 : ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n",
      "OKT 품사 태깅 : [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n",
      "OKT 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma()\n",
    "\n",
    "print(\"OKT 형태소 분석 :\", okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(\"OKT 품사 태깅 :\", okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(\"OKT 명사 추출 :\", okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼬꼬마 형태소 분석 : ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n",
      "꼬꼬마 품사 태깅 : [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n",
      "꼬꼬마 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
     ]
    }
   ],
   "source": [
    "print(\"꼬꼬마 형태소 분석 :\", kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(\"꼬꼬마 품사 태깅 :\", kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print(\"꼬꼬마 명사 추출 :\", kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09-02 텍스트 데이터의 정제와 정규화\n",
    "1. 토큰화 작업 전, 후에는 텍스트 데이터를 정제(cleaning), 정규화(normalization) 함께 해야함.\n",
    "- cleaning : 갖고 있는 코퍼스로부터 노이즈 데이터 제거\n",
    "- normalization : 표현 방법이 다른 단어들을 통합시켜 같은 단어로 만들어줌\n",
    "\n",
    "2. 규칙에 기반한 표기가 다른 단어 통합\n",
    "- USA, US\n",
    "- uh-huh, uhhuh\n",
    "\n",
    "3. 대, 소문자 통합\n",
    "- 모두 소문자로 통합하면 문제 생김\n",
    "    - US(미국), us(우리)\n",
    "    - General Motors, Bush 회사이름, 사람이름은 대문자 유지\n",
    "- 문장의 첫 단어의 대문자만 소문자로 바꾸는 방법\n",
    "- 훈련에 사용하는 Corpus가 대,소문자 규칙에 어긋나게 썼다면 그냥 소문자로 다 통합하는게 좋을때도 있음\n",
    "\n",
    "4. 불필요한 단어 제거\n",
    "    1. 등장 빈도가 적은 단어\n",
    "    2. 길이가 짧은 단어\n",
    "        - 영어에서 효과적이라고 알려짐\n",
    "        - 한국어 단어는 영어보다 평균적으로 짧음\n",
    "\n",
    "5. 정규 표현식\n",
    "- 규칙기반으로 cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " was wondering anyone out there could enlighten this car.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
    "\n",
    "# 길이가 1~2인 단어들을 정규 표현식을 이용하여 삭제\n",
    "shortword = re.compile(r\"\\W*\\b\\w{1,2}\\b\")\n",
    "print(shortword.sub(\"\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09-03 Stopwords\n",
    "1. 자주 등장하지만 분석에 큰 도움이 되지 않는 단어\n",
    "    - I,my,me,over,조사,접미사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/solkim/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 198\n",
      "불용어 10개 출력 : ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n"
     ]
    }
   ],
   "source": [
    "# NLTK에서 불용어 확인하기 (Natural Language Toolkit)\n",
    "stop_words_list = stopwords.words(\"english\")\n",
    "print(\"불용어 개수 :\", len(stop_words_list))\n",
    "print(\"불용어 10개 출력 :\", stop_words_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK를 통해서 불용어 제거하기\n",
    "example = \"Family is not an important thing. It's everything.\"\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for word in word_tokens:\n",
    "    if word not in stop_words:\n",
    "        result.append(word)\n",
    "\n",
    "print(\"불용어 제거 전 :\", word_tokens)\n",
    "print(\"불용어 제거 후 :\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
      "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\"\n",
    "\n",
    "stop_words = set(stop_words.split(\" \"))\n",
    "word_tokens = okt.morphs(example)\n",
    "\n",
    "result = [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "print(\"불용어 제거 전 :\", word_tokens)\n",
    "print(\"불용어 제거 후 :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규 표현식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 3), match='abc'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1. . 기호\n",
    "# 한개의 임의의 문자를 나타냄 a.c 는 abc, azc, adc , a!c와 같은 형태는 매치\n",
    "r = re.compile(\"a.c\")\n",
    "print(r.search(\"kkk\"))\n",
    "print(r.search(\"abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 3), match='abc'>\n",
      "<re.Match object; span=(0, 2), match='ac'>\n"
     ]
    }
   ],
   "source": [
    "# 2. ? 기호\n",
    "# ?앞의 문자가 존재할수도 존재하지 않을수도 있음을 나타냄\n",
    "# ab?c -> abc, ac 둘다 매치\n",
    "r = re.compile(\"ab?c\")\n",
    "print(r.search(\"abbc\"))\n",
    "print(r.search(\"abc\"))\n",
    "print(r.search(\"ac\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 2), match='ac'>\n",
      "<re.Match object; span=(0, 3), match='abc'>\n",
      "<re.Match object; span=(0, 9), match='abbbbbbbc'>\n"
     ]
    }
   ],
   "source": [
    "# 3. *기호\n",
    "# *바로앞의 문자가 0개 이상일 경우를 나타냄\n",
    "# 존재하지 않을수도 있고 또는 여러개일수도 있음\n",
    "# ab*c -> ac, abc, abbc, abbbc\n",
    "\n",
    "r = re.compile(\"ab*c\")\n",
    "print(r.search(\"a\"))\n",
    "print(r.search(\"ac\"))\n",
    "print(r.search(\"abc\"))\n",
    "print(r.search(\"abbbbbbbc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 9), match='abbbbbbbc'>\n"
     ]
    }
   ],
   "source": [
    "# 4. +기호\n",
    "# *와 유사하나 최소 1개이상\n",
    "\n",
    "r = re.compile(\"ab+c\")\n",
    "print(r.search(\"ac\"))\n",
    "print(r.search(\"abbbbbbbc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 2), match='ab'>\n"
     ]
    }
   ],
   "source": [
    "# 5. ^기호\n",
    "# 시작되는 문자열 지정\n",
    "# ^ab -> ab로 시작하는 문자열 매칭\n",
    "\n",
    "r = re.compile(\"^ab\")\n",
    "print(r.search(\"bbc\"))\n",
    "print(r.search(\"abccsad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 4), match='abbc'>\n"
     ]
    }
   ],
   "source": [
    "# 6. {숫자} 기호\n",
    "# 문자에 {숫자}를 붙이면 해당 문자를 숫자만큼 반복한 것을 나타냄\n",
    "# ab{2}c 라면 a와 c사이에 b가 존재하면서 b가 2개\n",
    "\n",
    "r = re.compile(\"ab{2}c\")\n",
    "print(r.search(\"ac\"))\n",
    "print(r.search(\"abbc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 4), match='abbc'>\n",
      "<re.Match object; span=(0, 10), match='abbbbbbbbc'>\n"
     ]
    }
   ],
   "source": [
    "# 7. {숫자1, 숫자2}기호\n",
    "# 문자에 해당 기호를 붙이면 해당 문자를 숫자1이상~숫자2이하만큼 반복\n",
    "\n",
    "r = re.compile(\"ab{2,8}c\")\n",
    "print(r.search(\"ac\"))\n",
    "print(r.search(\"abbc\"))\n",
    "print(r.search(\"abbbbbbbbc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 4), match='abbc'>\n",
      "<re.Match object; span=(0, 13), match='abbbbbbbbbbbc'>\n"
     ]
    }
   ],
   "source": [
    "# 8. {숫자, } 기호\n",
    "# 문자에 해당 기호를 붙이면 해당 문자를 숫자 이상만큼 반복\n",
    "\n",
    "r = re.compile(\"ab{2,}c\")\n",
    "print(r.search(\"abc\"))\n",
    "print(r.search(\"abbc\"))\n",
    "print(r.search(\"abbbbbbbbbbbc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 1), match='a'>\n",
      "<re.Match object; span=(0, 1), match='a'>\n",
      "<re.Match object; span=(0, 1), match='b'>\n"
     ]
    }
   ],
   "source": [
    "# 9. []기호\n",
    "# []안에 문자들을 넣으면 그 문자들 중 한개의 문자와 매치\n",
    "# [abc] a or b or c가 들어가있는 문자열과 매치\n",
    "# 범위 지정도 가능 [a-zA-Z]는 알파벳 전부\n",
    "# [0-9]는 숫자 전부\n",
    "\n",
    "r = re.compile(\"[abc]\")\n",
    "print(r.search(\"zzz\"))\n",
    "print(r.search(\"a\"))\n",
    "print(r.search(\"aaaaaaa\"))\n",
    "print(r.search(\"bcabca\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "<re.Match object; span=(0, 1), match='a'>\n"
     ]
    }
   ],
   "source": [
    "r = re.compile(\"[a-z]\")\n",
    "print(r.search(\"AAA\"))\n",
    "print(r.search(\"111\"))\n",
    "print(r.search(\"asuFD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(0, 1), match='d'>\n",
      "<re.Match object; span=(0, 1), match='1'>\n"
     ]
    }
   ],
   "source": [
    "# 10. [^문자] 기호\n",
    "# ^기호 뒤에 붙은 문자들을 제외한 모든 문자를 매치\n",
    "# [^abc] a or b or c가 들어간 문자열을 제외한 모든 문자열 매치\n",
    "\n",
    "r = re.compile(\"[^abc]\")\n",
    "print(r.search(\"a\"))\n",
    "print(r.search(\"ab\"))\n",
    "print(r.search(\"b\"))\n",
    "print(r.search(\"d\"))\n",
    "print(r.search(\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(3, 6), match='abc'>\n"
     ]
    }
   ],
   "source": [
    "# 정규 표현식 모듈 함수 예제\n",
    "# re.match() 와 re.search()의 차이\n",
    "# search 는 문자열 전체에서 정규표현식과 매치하는지 봄\n",
    "# match 는 문자열 첫 부분부터 매치하는지 확인, 시작 부분이 매치하지 않으면 찾지 않음\n",
    "\n",
    "r = re.compile(\"ab.\")\n",
    "print(r.match(\"kkkabc\"))\n",
    "print(r.search(\"kkkabc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과', '딸기', '수박', '메론', '바나나']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.split()\n",
    "# 정규표현식을 기준으로 문자열들을 분리하려 리스트로 리턴\n",
    "# 공백 기준 분리\n",
    "text = \"사과 딸기 수박 메론 바나나\"\n",
    "re.split(\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과', '딸기', '수박', '메론', '바나나']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 줄바꿈 기준 분리\n",
    "text = \"\"\"사과\n",
    "딸기\n",
    "수박\n",
    "메론\n",
    "바나나\"\"\"\n",
    "\n",
    "re.split(\"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사괴', '딸기', '수박', '메론', '바나나']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '+'를 기준으로 분리\n",
    "text = \"사괴+딸기+수박+메론+바나나\"\n",
    "re.split(\"\\+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['010', '1234', '1234', '30']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# re.findall()\n",
    "# findall()함수는 정규 표현식과 매치되는 모든 문자열들을 리스트로 리턴\n",
    "# 매치되는 문자열 없으면 빈 리스트 리턴\n",
    "\n",
    "text = \"\"\"이름 : 김철수\n",
    "전화번호 : 010 - 1234 - 1234\n",
    "나이 : 30\n",
    "성별 : 남\"\"\"\n",
    "\n",
    "print(re.findall(\"\\d+\", text))  # 전체 텍스트에서 숫자만 찾아서 리턴\n",
    "print(re.findall(\"\\d+\", \"문자열입니다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n"
     ]
    }
   ],
   "source": [
    "# re.sub()\n",
    "# 정규표현식 패턴과 일치하는 문자열 찾아 다른 문자열로 대체\n",
    "text = \"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
    "\n",
    "preprocessed_text = re.sub(\"[^a-zA-Z]\", \" \", text)  # 영어알파벳이 아닌것을 공백으로\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']\n",
      "['100', '101', '102']\n",
      "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']\n",
      "['PROF', 'STUD', 'STUD']\n",
      "['John', 'James', 'Mac']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"100 John    PROF\n",
    "101 James   STUD\n",
    "102 Mac   STUD\"\"\"\n",
    "\n",
    "print(re.split(\"\\s+\", text))  # 공백을 찾아내는 정규표현식\n",
    "print(re.findall(\"\\d+\", text))  # 숫자 최소 한개\n",
    "print(\n",
    "    re.findall(\"[A-Z]\", text)\n",
    ")  # 대문자 찾기, 문자열을 가져오는게 아니라 대문자 각각을 가져옴\n",
    "print(re.findall(\"[A-Z]{4}\", text))  # 대문자가 연속 4개이상 등장하는 경우\n",
    "print(re.findall(\"[A-Z][a-z]+\", text))  # 처음에는 대문자 그 뒤에 소문자 여러개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
      "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
    "\n",
    "tokenizer1 = RegexpTokenizer(\"[\\w]+\")  # 문자 또는 숫자가 1개이상인경우\n",
    "tokenizer2 = RegexpTokenizer(\"\\s+\", gaps=True)  # 공백기준\n",
    "\n",
    "print(tokenizer1.tokenize(text))\n",
    "print(tokenizer2.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어처리 토큰화 -> 단어 집합 생성 -> 정수 인코딩 -> 패딩 -> 벡터화\n",
    "en_text = \"A Dog Run back corner near spare bedrooms\"\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy # 토큰화 라이브러리\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(spacy_en.tokenizer(en_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(en_text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(en_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(en_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from nltk) (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/solkim/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(en_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기로 토큰화\n",
    "print(en_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사과의', '놀라운', '효능이라는', '글을', '봤어.', '그래서', '오늘', '사과를', '먹으려고', '했는데', '사과가', '썩어서', '슈퍼에', '가서', '사과랑', '오렌지', '사왔어']\n"
     ]
    }
   ],
   "source": [
    "# 한국어 띄어쓰기 토큰화\n",
    "kor_text = \"사과의 놀라운 효능이라는 글을 봤어. 그래서 오늘 사과를 먹으려고 했는데 사과가 썩어서 슈퍼에 가서 사과랑 오렌지 사왔어\"\n",
    "print(kor_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 토큰화\n",
    "!pip install konlpy\n",
    "!pip install mecab-python\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사과', '의', '놀라운', '효능', '이', '라는', '글', '을', '봤', '어', '.', '그래서', '오늘', '사과', '를', '먹', '으려고', '했', '는데', '사과', '가', '썩', '어서', '슈퍼', '에', '가', '서', '사과', '랑', '오렌지', '사', '왔', '어']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "tokenizer = Mecab()\n",
    "print(tokenizer.morphs(kor_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', ' ', 'D', 'o', 'g', ' ', 'R', 'u', 'n', ' ', 'b', 'a', 'c', 'k', ' ', 'c', 'o', 'r', 'n', 'e', 'r', ' ', 'n', 'e', 'a', 'r', ' ', 's', 'p', 'a', 'r', 'e', ' ', 'b', 'e', 'd', 'r', 'o', 'o', 'm', 's']\n"
     ]
    }
   ],
   "source": [
    "# 문자 토큰화\n",
    "print(list(en_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합 생성\n",
    "# 중복을 제거한 텍스트의 총 단어의 집합\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "from nltk import FreqDist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2190435</td>\n",
       "      <td>사랑을 해본사람이라면 처음부터 끝까지 웃을수 있는영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9279041</td>\n",
       "      <td>완전 감동입니다 다시봐도 감동</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7865729</td>\n",
       "      <td>개들의 전쟁2 나오나요? 나오면 1빠로 보고 싶음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7477618</td>\n",
       "      <td>굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9250537</td>\n",
       "      <td>바보가 아니라 병 쉰 인듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1\n",
       "5   2190435                      사랑을 해본사람이라면 처음부터 끝까지 웃을수 있는영화      1\n",
       "6   9279041                                   완전 감동입니다 다시봐도 감동      1\n",
       "7   7865729                        개들의 전쟁2 나오나요? 나오면 1빠로 보고 싶음      1\n",
       "8   7477618                                                  굿      1\n",
       "9   9250537                                     바보가 아니라 병 쉰 인듯      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\",\n",
    "    filename=\"ratings.txt\",\n",
    ")\n",
    "data = pd.read_table(\"ratings.txt\")  # 데이터프레임에 저장\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 200000\n"
     ]
    }
   ],
   "source": [
    "print(f\"전체 샘플의 수 : {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data[:100]  # 임의로 100개만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/lh2cbhl94cd4db2dsg3x2blh0000gn/T/ipykernel_62261/172372675.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_data['document'] = sample_data['document'].str.replace(\"[^ㄱ-하-ㅣ가-힣]\", \"\", regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고지금다시봐도재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을배우는학생으로외국디자이너와그들이일군전통을통해발전해가는문화산업이부러웠는데사실우...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리시리즈는부터뉴까지버릴께하나도없음최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와연기가진짜개쩔구나지루할거라고생각했는데몰입해서봤다그래이런게진짜영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개자욱한밤하늘에떠있는초승달같은영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2190435</td>\n",
       "      <td>사랑을해본사람이라면처음부터끝까지웃을수있는영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9279041</td>\n",
       "      <td>완전감동입니다다시봐도감동</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7865729</td>\n",
       "      <td>개들의전쟁나오나요나오면빠로보고싶음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7477618</td>\n",
       "      <td>굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9250537</td>\n",
       "      <td>바보가아니라병쉰인듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                  어릴때보고지금다시봐도재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을배우는학생으로외국디자이너와그들이일군전통을통해발전해가는문화산업이부러웠는데사실우...      1\n",
       "2   4655635                          폴리스스토리시리즈는부터뉴까지버릴께하나도없음최고      1\n",
       "3   9251303              와연기가진짜개쩔구나지루할거라고생각했는데몰입해서봤다그래이런게진짜영화지      1\n",
       "4  10067386                                안개자욱한밤하늘에떠있는초승달같은영화      1\n",
       "5   2190435                           사랑을해본사람이라면처음부터끝까지웃을수있는영화      1\n",
       "6   9279041                                      완전감동입니다다시봐도감동      1\n",
       "7   7865729                                 개들의전쟁나오나요나오면빠로보고싶음      1\n",
       "8   7477618                                                  굿      1\n",
       "9   9250537                                         바보가아니라병쉰인듯      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식으로 데이터 정제\n",
    "sample_data[\"document\"] = sample_data[\"document\"].str.replace(\n",
    "    \"[^ㄱ-하-ㅣ가-힣]\", \"\", regex=True\n",
    ")\n",
    "# 한글과 공백을 제외하고 모두 제거\n",
    "sample_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = [\n",
    "    \"의\",\n",
    "    \"가\",\n",
    "    \"이\",\n",
    "    \"은\",\n",
    "    \"들\",\n",
    "    \"는\",\n",
    "    \"좀\",\n",
    "    \"잘\",\n",
    "    \"걍\",\n",
    "    \"과\",\n",
    "    \"도\",\n",
    "    \"를\",\n",
    "    \"으로\",\n",
    "    \"자\",\n",
    "    \"에\",\n",
    "    \"와\",\n",
    "    \"한\",\n",
    "    \"하다\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Mecab()\n",
    "tokenized = []\n",
    "for sentence in sample_data[\"document\"]:\n",
    "    temp = tokenizer.morphs(sentence)  # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords]  # 불용어 제거\n",
    "    tokenized.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ'], ['디자인', '을', '배우', '학생', '외국', '디자이너', '그', '일군', '전통', '을', '통해', '발전', '해', '문화', '산업', '부러웠', '는데', '사실', '우리', '나라', '에서', '그', '어려운', '시절', '끝', '까지', '열정', '을', '지킨', '노라노', '같', '전통', '있', '어', '저', '같', '사람', '꿈', '을', '꾸', '고', '이뤄나갈', '수', '있', '다는', '것', '감사', '합니다'], ['폴리스', '스토리', '시리즈', '부터', '뉴', '까지', '버릴', '께', '하나', '없', '음', '최고'], ['연기', '진짜', '개', '쩔', '구나', '지루', '할거', '라고', '생각', '했', '는데', '몰입', '해서', '봤', '다', '그래', '이런', '게', '진짜', '영화', '지'], ['안개', '자욱', '밤하늘', '떠', '있', '초승달', '같', '영화'], ['사랑', '을', '해', '본', '사람', '라면', '처음', '부터', '끝', '까지', '웃', '을', '수', '있', '영화'], ['완전', '감동', '입니다', '다시', '봐도', '감동'], ['개', '전쟁', '나오', '나요', '나오', '면', '빠', '로', '보', '고', '싶', '음'], ['굿'], ['바보', '아니', '라', '병', '쉰', '인', '듯']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 656\n"
     ]
    }
   ],
   "source": [
    "vocab = FreqDist(np.hstack(tokenized))  # 단어 빈도 계산\n",
    "print(f\"단어 집합의 크기 : {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"재밌\"]  # 단어를 key, 빈도수를 value로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.str_('다'), 42),\n",
       " (np.str_('영화'), 31),\n",
       " (np.str_('고'), 27),\n",
       " (np.str_('을'), 24),\n",
       " (np.str_('하'), 22),\n",
       " (np.str_('있'), 18),\n",
       " (np.str_('게'), 15),\n",
       " (np.str_('보'), 14),\n",
       " (np.str_('최고'), 13),\n",
       " (np.str_('좋'), 13),\n",
       " (np.str_('는데'), 12),\n",
       " (np.str_('없'), 12),\n",
       " (np.str_('같'), 10),\n",
       " (np.str_('수'), 10),\n",
       " (np.str_('봤'), 10),\n",
       " (np.str_('적'), 10),\n",
       " (np.str_('었'), 10),\n",
       " (np.str_('할'), 9),\n",
       " (np.str_('만'), 9),\n",
       " (np.str_('정말'), 9),\n",
       " (np.str_('재밌'), 8),\n",
       " (np.str_('해'), 8),\n",
       " (np.str_('였'), 8),\n",
       " (np.str_('때'), 7),\n",
       " (np.str_('어요'), 7),\n",
       " (np.str_('에서'), 7),\n",
       " (np.str_('까지'), 7),\n",
       " (np.str_('음'), 7),\n",
       " (np.str_('진짜'), 7),\n",
       " (np.str_('했'), 7),\n",
       " (np.str_('지'), 7),\n",
       " (np.str_('본'), 7),\n",
       " (np.str_('감동'), 7),\n",
       " (np.str_('로'), 7),\n",
       " (np.str_('내'), 7),\n",
       " (np.str_('네요'), 7),\n",
       " (np.str_('다시'), 6),\n",
       " (np.str_('사람'), 6),\n",
       " (np.str_('것'), 6),\n",
       " (np.str_('생각'), 6),\n",
       " (np.str_('싶'), 6),\n",
       " (np.str_('나'), 6),\n",
       " (np.str_('아'), 6),\n",
       " (np.str_('너무'), 6),\n",
       " (np.str_('으면'), 6),\n",
       " (np.str_('지금'), 5),\n",
       " (np.str_('그'), 5),\n",
       " (np.str_('사실'), 5),\n",
       " (np.str_('저'), 5),\n",
       " (np.str_('부터'), 5),\n",
       " (np.str_('하나'), 5),\n",
       " (np.str_('연기'), 5),\n",
       " (np.str_('나오'), 5),\n",
       " (np.str_('굿'), 5),\n",
       " (np.str_('인'), 5),\n",
       " (np.str_('왜'), 5),\n",
       " (np.str_('네'), 5),\n",
       " (np.str_('년'), 5),\n",
       " (np.str_('마음'), 5),\n",
       " (np.str_('거'), 5),\n",
       " (np.str_('지만'), 5),\n",
       " (np.str_('어'), 4),\n",
       " (np.str_('라고'), 4),\n",
       " (np.str_('이런'), 4),\n",
       " (np.str_('았'), 4),\n",
       " (np.str_('평점'), 4),\n",
       " (np.str_('된'), 4),\n",
       " (np.str_('말'), 4),\n",
       " (np.str_('기'), 4),\n",
       " (np.str_('속'), 4),\n",
       " (np.str_('면서'), 4),\n",
       " (np.str_('주'), 4),\n",
       " (np.str_('뭐'), 4),\n",
       " (np.str_('재미있'), 4),\n",
       " (np.str_('건'), 4),\n",
       " (np.str_('중'), 4),\n",
       " (np.str_('어릴'), 3),\n",
       " (np.str_('봐도'), 3),\n",
       " (np.str_('ㅋㅋ'), 3),\n",
       " (np.str_('배우'), 3),\n",
       " (np.str_('우리'), 3),\n",
       " (np.str_('다는'), 3),\n",
       " (np.str_('합니다'), 3),\n",
       " (np.str_('웃'), 3),\n",
       " (np.str_('면'), 3),\n",
       " (np.str_('아니'), 3),\n",
       " (np.str_('라'), 3),\n",
       " (np.str_('듯'), 3),\n",
       " (np.str_('전'), 3),\n",
       " (np.str_('낮'), 3),\n",
       " (np.str_('인데'), 3),\n",
       " (np.str_('던'), 3),\n",
       " (np.str_('마지막'), 3),\n",
       " (np.str_('대한'), 3),\n",
       " (np.str_('명작'), 3),\n",
       " (np.str_('될'), 3),\n",
       " (np.str_('는지'), 3),\n",
       " (np.str_('안'), 3),\n",
       " (np.str_('볼'), 3),\n",
       " (np.str_('이거'), 3),\n",
       " (np.str_('재'), 3),\n",
       " (np.str_('친구'), 3),\n",
       " (np.str_('또'), 3),\n",
       " (np.str_('방'), 3),\n",
       " (np.str_('재미'), 3),\n",
       " (np.str_('느낌'), 3),\n",
       " (np.str_('남자'), 3),\n",
       " (np.str_('되'), 3),\n",
       " (np.str_('매력'), 3),\n",
       " (np.str_('ㅎ'), 3),\n",
       " (np.str_('습니다'), 3),\n",
       " (np.str_('전통'), 2),\n",
       " (np.str_('문화'), 2),\n",
       " (np.str_('나라'), 2),\n",
       " (np.str_('시절'), 2),\n",
       " (np.str_('끝'), 2),\n",
       " (np.str_('스토리'), 2),\n",
       " (np.str_('개'), 2),\n",
       " (np.str_('해서'), 2),\n",
       " (np.str_('사랑'), 2),\n",
       " (np.str_('라면'), 2),\n",
       " (np.str_('처음'), 2),\n",
       " (np.str_('완전'), 2),\n",
       " (np.str_('감정'), 2),\n",
       " (np.str_('화'), 2),\n",
       " (np.str_('해야'), 2),\n",
       " (np.str_('작품'), 2),\n",
       " (np.str_('긴장감'), 2),\n",
       " (np.str_('랑'), 2),\n",
       " (np.str_('갈수록'), 2),\n",
       " (np.str_('더욱'), 2),\n",
       " (np.str_('서'), 2),\n",
       " (np.str_('남'), 2),\n",
       " (np.str_('역시'), 2),\n",
       " (np.str_('씬'), 2),\n",
       " (np.str_('잊'), 2),\n",
       " (np.str_('용서'), 2),\n",
       " (np.str_('비판'), 2),\n",
       " (np.str_('시대'), 2),\n",
       " (np.str_('시간'), 2),\n",
       " (np.str_('죽'), 2),\n",
       " (np.str_('아름답'), 2),\n",
       " (np.str_('기억'), 2),\n",
       " (np.str_('여러'), 2),\n",
       " (np.str_('왔'), 2),\n",
       " (np.str_('일'), 2),\n",
       " (np.str_('어디'), 2),\n",
       " (np.str_('알'), 2),\n",
       " (np.str_('우정'), 2),\n",
       " (np.str_('해라'), 2),\n",
       " (np.str_('못'), 2),\n",
       " (np.str_('내내'), 2),\n",
       " (np.str_('샤'), 2),\n",
       " (np.str_('많이'), 2),\n",
       " (np.str_('그런가'), 2),\n",
       " (np.str_('흥미진진'), 2),\n",
       " (np.str_('ㄷ'), 2),\n",
       " (np.str_('ㅋㅋㅋ'), 2),\n",
       " (np.str_('티비'), 2),\n",
       " (np.str_('모르'), 2),\n",
       " (np.str_('인정'), 2),\n",
       " (np.str_('그대'), 2),\n",
       " (np.str_('넘'), 2),\n",
       " (np.str_('내용'), 2),\n",
       " (np.str_('아요'), 2),\n",
       " (np.str_('한다'), 2),\n",
       " (np.str_('밋'), 2),\n",
       " (np.str_('음악'), 2),\n",
       " (np.str_('드라마'), 2),\n",
       " (np.str_('겠'), 2),\n",
       " (np.str_('가지'), 2),\n",
       " (np.str_('싫'), 2),\n",
       " (np.str_('어서'), 2),\n",
       " (np.str_('훌륭'), 2),\n",
       " (np.str_('엔'), 2),\n",
       " (np.str_('첫'), 2),\n",
       " (np.str_('너무너무'), 2),\n",
       " (np.str_('보다'), 2),\n",
       " (np.str_('가을'), 2),\n",
       " (np.str_('연기자'), 2),\n",
       " (np.str_('요'), 2),\n",
       " (np.str_('했었'), 2),\n",
       " (np.str_('장르'), 2),\n",
       " (np.str_('디자인'), 1),\n",
       " (np.str_('학생'), 1),\n",
       " (np.str_('외국'), 1),\n",
       " (np.str_('디자이너'), 1),\n",
       " (np.str_('일군'), 1),\n",
       " (np.str_('통해'), 1),\n",
       " (np.str_('발전'), 1),\n",
       " (np.str_('산업'), 1),\n",
       " (np.str_('부러웠'), 1),\n",
       " (np.str_('어려운'), 1),\n",
       " (np.str_('열정'), 1),\n",
       " (np.str_('지킨'), 1),\n",
       " (np.str_('노라노'), 1),\n",
       " (np.str_('꿈'), 1),\n",
       " (np.str_('꾸'), 1),\n",
       " (np.str_('이뤄나갈'), 1),\n",
       " (np.str_('감사'), 1),\n",
       " (np.str_('폴리스'), 1),\n",
       " (np.str_('시리즈'), 1),\n",
       " (np.str_('뉴'), 1),\n",
       " (np.str_('버릴'), 1),\n",
       " (np.str_('께'), 1),\n",
       " (np.str_('쩔'), 1),\n",
       " (np.str_('구나'), 1),\n",
       " (np.str_('지루'), 1),\n",
       " (np.str_('할거'), 1),\n",
       " (np.str_('몰입'), 1),\n",
       " (np.str_('그래'), 1),\n",
       " (np.str_('안개'), 1),\n",
       " (np.str_('자욱'), 1),\n",
       " (np.str_('밤하늘'), 1),\n",
       " (np.str_('떠'), 1),\n",
       " (np.str_('초승달'), 1),\n",
       " (np.str_('입니다'), 1),\n",
       " (np.str_('전쟁'), 1),\n",
       " (np.str_('나요'), 1),\n",
       " (np.str_('빠'), 1),\n",
       " (np.str_('바보'), 1),\n",
       " (np.str_('병'), 1),\n",
       " (np.str_('쉰'), 1),\n",
       " (np.str_('나이'), 1),\n",
       " (np.str_('하지만'), 1),\n",
       " (np.str_('훗날'), 1),\n",
       " (np.str_('보면대'), 1),\n",
       " (np.str_('사'), 1),\n",
       " (np.str_('완벽'), 1),\n",
       " (np.str_('이해'), 1),\n",
       " (np.str_('고질라'), 1),\n",
       " (np.str_('니무'), 1),\n",
       " (np.str_('귀엽'), 1),\n",
       " (np.str_('능'), 1),\n",
       " (np.str_('오페라'), 1),\n",
       " (np.str_('극단'), 1),\n",
       " (np.str_('적평'), 1),\n",
       " (np.str_('갈림'), 1),\n",
       " (np.str_('어쩔'), 1),\n",
       " (np.str_('도반'), 1),\n",
       " (np.str_('제'), 1),\n",
       " (np.str_('스릴감'), 1),\n",
       " (np.str_('전장'), 1),\n",
       " (np.str_('느끼'), 1),\n",
       " (np.str_('공포'), 1),\n",
       " (np.str_('생생'), 1),\n",
       " (np.str_('전해준다'), 1),\n",
       " (np.str_('고시'), 1),\n",
       " (np.str_('이터'), 1),\n",
       " (np.str_('소재'), 1),\n",
       " (np.str_('뿐'), 1),\n",
       " (np.str_('아무런'), 1),\n",
       " (np.str_('관련'), 1),\n",
       " (np.str_('단연'), 1),\n",
       " (np.str_('빠져드'), 1),\n",
       " (np.str_('밀회'), 1),\n",
       " (np.str_('화이팅'), 1),\n",
       " (np.str_('생각없이'), 1),\n",
       " (np.str_('상당'), 1),\n",
       " (np.str_('수작'), 1),\n",
       " (np.str_('일본'), 1),\n",
       " (np.str_('강렬'), 1),\n",
       " (np.str_('임팩트'), 1),\n",
       " (np.str_('일품'), 1),\n",
       " (np.str_('오랜만'), 1),\n",
       " (np.str_('제대로'), 1),\n",
       " (np.str_('범죄'), 1),\n",
       " (np.str_('스릴러'), 1),\n",
       " (np.str_('그런'), 1),\n",
       " (np.str_('해도'), 1),\n",
       " (np.str_('그저'), 1),\n",
       " (np.str_('한다는'), 1),\n",
       " (np.str_('한마디'), 1),\n",
       " (np.str_('꺼내'), 1),\n",
       " (np.str_('벅차'), 1),\n",
       " (np.str_('밤잠'), 1),\n",
       " (np.str_('설치'), 1),\n",
       " (np.str_('커'), 1),\n",
       " (np.str_('징'), 1),\n",
       " (np.str_('텅'), 1),\n",
       " (np.str_('교복'), 1),\n",
       " (np.str_('션'), 1),\n",
       " (np.str_('자이'), 1),\n",
       " (np.str_('볼펜'), 1),\n",
       " (np.str_('자국'), 1),\n",
       " (np.str_('미처'), 1),\n",
       " (np.str_('다전'), 1),\n",
       " (np.str_('못한'), 1),\n",
       " (np.str_('형태'), 1),\n",
       " (np.str_('강압'), 1),\n",
       " (np.str_('세뇌'), 1),\n",
       " (np.str_('중세'), 1),\n",
       " (np.str_('이래'), 1),\n",
       " (np.str_('짜리'), 1),\n",
       " (np.str_('영상'), 1),\n",
       " (np.str_('존재'), 1),\n",
       " (np.str_('한다면'), 1),\n",
       " (np.str_('꼭'), 1),\n",
       " (np.str_('한번'), 1),\n",
       " (np.str_('슬픈'), 1),\n",
       " (np.str_('제니퍼코넬리'), 1),\n",
       " (np.str_('눈부신'), 1),\n",
       " (np.str_('아역'), 1),\n",
       " (np.str_('로버트드니로'), 1),\n",
       " (np.str_('장면'), 1),\n",
       " (np.str_('가슴'), 1),\n",
       " (np.str_('영원히'), 1),\n",
       " (np.str_('어떻'), 1),\n",
       " (np.str_('저런'), 1),\n",
       " (np.str_('짓'), 1),\n",
       " (np.str_('ㅡㅡ보는내가다화나더라'), 1),\n",
       " (np.str_('인간'), 1),\n",
       " (np.str_('잠재'), 1),\n",
       " (np.str_('악마'), 1),\n",
       " (np.str_('성'), 1),\n",
       " (np.str_('공간'), 1),\n",
       " (np.str_('존속'), 1),\n",
       " (np.str_('다큐'), 1),\n",
       " (np.str_('그것'), 1),\n",
       " (np.str_('엉뚱'), 1),\n",
       " (np.str_('도광'), 1),\n",
       " (np.str_('재현'), 1),\n",
       " (np.str_('삼'), 1),\n",
       " (np.str_('동안'), 1),\n",
       " (np.str_('쉬'), 1),\n",
       " (np.str_('틈틈이'), 1),\n",
       " (np.str_('잠'), 1),\n",
       " (np.str_('줄여'), 1),\n",
       " (np.str_('여운'), 1),\n",
       " (np.str_('는다'), 1),\n",
       " (np.str_('실화'), 1),\n",
       " (np.str_('여서'), 1),\n",
       " (np.str_('충격'), 1),\n",
       " (np.str_('일어나'), 1),\n",
       " (np.str_('경각심'), 1),\n",
       " (np.str_('일깨워'), 1),\n",
       " (np.str_('존'), 1),\n",
       " (np.str_('그라'), 1),\n",
       " (np.str_('샴'), 1),\n",
       " (np.str_('번'), 1),\n",
       " (np.str_('쯤'), 1),\n",
       " (np.str_('가치'), 1),\n",
       " (np.str_('농아'), 1),\n",
       " (np.str_('아야'), 1),\n",
       " (np.str_('어렸'), 1),\n",
       " (np.str_('되게'), 1),\n",
       " (np.str_('밌게봄ㅋㅋ이정재이범수ㅋㅋㅋㅋ연기쩜'), 1),\n",
       " (np.str_('매우'), 1),\n",
       " (np.str_('제발'), 1),\n",
       " (np.str_('ㅠㅠ'), 1),\n",
       " (np.str_('아재미'), 1),\n",
       " (np.str_('어울린다'), 1),\n",
       " (np.str_('제이크질렌할'), 1),\n",
       " (np.str_('넌'), 1),\n",
       " (np.str_('대체'), 1),\n",
       " (np.str_('냐'), 1),\n",
       " (np.str_('입가'), 1),\n",
       " (np.str_('미소'), 1),\n",
       " (np.str_('원표'), 1),\n",
       " (np.str_('조연'), 1),\n",
       " (np.str_('양'), 1),\n",
       " (np.str_('젤'), 1),\n",
       " (np.str_('는구만'), 1),\n",
       " (np.str_('마치'), 1),\n",
       " (np.str_('바다'), 1),\n",
       " (np.str_('아쿠아리움'), 1),\n",
       " (np.str_('들어간'), 1),\n",
       " (np.str_('어린'), 1),\n",
       " (np.str_('자녀'), 1),\n",
       " (np.str_('에게'), 1),\n",
       " (np.str_('강추'), 1),\n",
       " (np.str_('정의'), 1),\n",
       " (np.str_('세우'), 1),\n",
       " (np.str_('콜트'), 1),\n",
       " (np.str_('콜'), 1),\n",
       " (np.str_('텍'), 1),\n",
       " (np.str_('노동자'), 1),\n",
       " (np.str_('이야기'), 1),\n",
       " (np.str_('브라질'), 1),\n",
       " (np.str_('사라질'), 1),\n",
       " (np.str_('난'), 1),\n",
       " (np.str_('울렸'), 1),\n",
       " (np.str_('그리고'), 1),\n",
       " (np.str_('두'), 1),\n",
       " (np.str_('여배우'), 1),\n",
       " (np.str_('도법'), 1),\n",
       " (np.str_('멤버'), 1),\n",
       " (np.str_('모두'), 1),\n",
       " (np.str_('기대'), 1),\n",
       " (np.str_('됨'), 1),\n",
       " (np.str_('액션'), 1),\n",
       " (np.str_('겁나'), 1),\n",
       " (np.str_('던데'), 1),\n",
       " (np.str_('워낙에'), 1),\n",
       " (np.str_('격투'), 1),\n",
       " (np.str_('좋아해서'), 1),\n",
       " (np.str_('그냥'), 1),\n",
       " (np.str_('아무'), 1),\n",
       " (np.str_('없이'), 1),\n",
       " (np.str_('집'), 1),\n",
       " (np.str_('스마트'), 1),\n",
       " (np.str_('봐서'), 1),\n",
       " (np.str_('봄'), 1),\n",
       " (np.str_('뭔'), 1),\n",
       " (np.str_('인지'), 1),\n",
       " (np.str_('암살'), 1),\n",
       " (np.str_('나온'), 1),\n",
       " (np.str_('이정재'), 1),\n",
       " (np.str_('길래'), 1),\n",
       " (np.str_('걍봄ㅋㅋ하여튼너무재밌게봤음'), 1),\n",
       " (np.str_('ㅆ'), 1),\n",
       " (np.str_('파르'), 1),\n",
       " (np.str_('북한'), 1),\n",
       " (np.str_('살만'), 1),\n",
       " (np.str_('목숨걸'), 1),\n",
       " (np.str_('대한민국'), 1),\n",
       " (np.str_('오'), 1),\n",
       " (np.str_('건데'), 1),\n",
       " (np.str_('그거'), 1),\n",
       " (np.str_('납득'), 1),\n",
       " (np.str_('시키'), 1),\n",
       " (np.str_('나불거려'), 1),\n",
       " (np.str_('종북'), 1),\n",
       " (np.str_('박평식'), 1),\n",
       " (np.str_('튼'), 1),\n",
       " (np.str_('여월'), 1),\n",
       " (np.str_('비'), 1),\n",
       " (np.str_('내려야'), 1),\n",
       " (np.str_('보이'), 1),\n",
       " (np.str_('시작'), 1),\n",
       " (np.str_('반가운'), 1),\n",
       " (np.str_('얼굴'), 1),\n",
       " (np.str_('여주인공'), 1),\n",
       " (np.str_('구'), 1),\n",
       " (np.str_('유쾌'), 1),\n",
       " (np.str_('요즘'), 1),\n",
       " (np.str_('아이'), 1),\n",
       " (np.str_('돌'), 1),\n",
       " (np.str_('먹'), 1),\n",
       " (np.str_('정도'), 1),\n",
       " (np.str_('봣는대요어디서받을수잇조'), 1),\n",
       " (np.str_('탱고'), 1),\n",
       " (np.str_('밀려'), 1),\n",
       " (np.str_('온다'), 1),\n",
       " (np.str_('평생'), 1),\n",
       " (np.str_('후회'), 1),\n",
       " (np.str_('뻔'), 1),\n",
       " (np.str_('따뜻'), 1),\n",
       " (np.str_('나왔'), 1),\n",
       " (np.str_('많'), 1),\n",
       " (np.str_('영상미'), 1),\n",
       " (np.str_('캐릭터'), 1),\n",
       " (np.str_('련결'), 1),\n",
       " (np.str_('ㅠ'), 1),\n",
       " (np.str_('슬프'), 1),\n",
       " (np.str_('이제'), 1),\n",
       " (np.str_('잔잔'), 1),\n",
       " (np.str_('중영'), 1),\n",
       " (np.str_('순위'), 1),\n",
       " (np.str_('상당히'), 1),\n",
       " (np.str_('신동엽'), 1),\n",
       " (np.str_('ㅋ'), 1),\n",
       " (np.str_('순간'), 1),\n",
       " (np.str_('캐치'), 1),\n",
       " (np.str_('탁'), 1),\n",
       " (np.str_('얄밉'), 1),\n",
       " (np.str_('긴'), 1),\n",
       " (np.str_('미워할'), 1),\n",
       " (np.str_('감탄'), 1),\n",
       " (np.str_('영'), 1),\n",
       " (np.str_('자랑'), 1),\n",
       " (np.str_('함'), 1),\n",
       " (np.str_('대박'), 1),\n",
       " (np.str_('텐데'), 1),\n",
       " (np.str_('왠'), 1),\n",
       " (np.str_('이동욱'), 1),\n",
       " (np.str_('내인생의'), 1),\n",
       " (np.str_('전작'), 1),\n",
       " (np.str_('비해'), 1),\n",
       " (np.str_('떨어지'), 1),\n",
       " (np.str_('쓰레기'), 1),\n",
       " (np.str_('한국'), 1),\n",
       " (np.str_('점대'), 1),\n",
       " (np.str_('별'), 1),\n",
       " (np.str_('헐'), 1),\n",
       " (np.str_('니'), 1),\n",
       " (np.str_('다소'), 1),\n",
       " (np.str_('진부'), 1),\n",
       " (np.str_('어도'), 1),\n",
       " (np.str_('당시'), 1),\n",
       " (np.str_('눈물'), 1),\n",
       " (np.str_('사발'), 1),\n",
       " (np.str_('흘리'), 1),\n",
       " (np.str_('준'), 1),\n",
       " (np.str_('신부'), 1),\n",
       " (np.str_('로서'), 1),\n",
       " (np.str_('사명감'), 1),\n",
       " (np.str_('처절히'), 1),\n",
       " (np.str_('실천'), 1),\n",
       " (np.str_('제리'), 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 500\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 500\n",
    "# 상위 vocab_size개의 단어만 보존\n",
    "vocab = vocab.most_common(vocab_size)\n",
    "print(f\"단어 집합의 크기 : {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어에 고유한 정수 부여\n",
    "word_to_index = {word[0]: index + 2 for index, word in enumerate(vocab)}\n",
    "word_to_index[\"pad\"] = 1\n",
    "word_to_index[\"unk\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 훈련 데이터에서 각 단어를 고유한 정수로 부여\n",
    "encoded = []\n",
    "for line in tokenized: # 입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp = []\n",
    "    for w in line: # 각 줄에서 1개씩 글자를 읽음\n",
    "        try:\n",
    "            temp.append(word_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "        except KeyError: # 단어 집합에 없는 단어일 경우 unk로 대체\n",
    "            temp.append(word_to_index['unk']) # unk의 인덱스로 변환\n",
    "    encoded.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78, 25, 9, 4, 47, 38, 79, 22, 26, 80], [185, 5, 81, 186, 187, 188, 48, 189, 113, 5, 190, 191, 23, 114, 192, 193, 12, 49, 82, 115, 27, 48, 194, 116, 117, 28, 195, 5, 196, 197, 14, 113, 7, 63, 50, 14, 39, 198, 5, 199, 4, 200, 15, 7, 83, 40, 201, 84], [202, 118, 203, 51, 204, 28, 205, 206, 52, 13, 29, 10], [53, 30, 119, 207, 208, 209, 210, 64, 41, 31, 12, 211, 120, 16, 2, 212, 65, 8, 30, 3, 32], [213, 214, 215, 216, 7, 217, 14, 3], [121, 5, 23, 33, 39, 122, 123, 51, 117, 28, 85, 5, 15, 7, 3], [124, 34, 218, 38, 79, 34], [119, 219, 54, 220, 54, 86, 221, 35, 9, 4, 42, 29], [55], [222, 87, 88, 223, 224, 56, 89]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 62\n",
      "리뷰의 최소 길이 : 1\n",
      "리뷰의 평균 길이 : 13.510000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이가 다른 문장들을 모두 동일한 길이로 바꿔주는 패딩(padding)\n",
    "# 길이가 정해준 길이보다 짧은 샘플들에 'pad'토큰 추가해서 길이 맞춰줌\n",
    "\n",
    "max_len = max(len(l) for l in encoded)\n",
    "print('리뷰의 최대 길이 : %d' %max_len)\n",
    "print('리뷰의 최소 길이 : %d' % min(len(l) for l in encoded))\n",
    "print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))\n",
    "\n",
    "plt.hist([len(s) for s in encoded], bins=50)\n",
    "plt.xlabel('length of sample')\n",
    "plt.ylabel('number of sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 리뷰 길이 62로 통일\n",
    "for line in encoded:\n",
    "    if len(line) < max_len:\n",
    "        line += [word_to_index['pad']] * (max_len - len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 62\n",
      "리뷰의 최소 길이 : 62\n",
      "리뷰의 평균 길이 : 62.000000\n"
     ]
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 : %d' %max_len)\n",
    "print('리뷰의 최소 길이 : %d' % min(len(l) for l in encoded))\n",
    "print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78, 25, 9, 4, 47, 38, 79, 22, 26, 80, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [185, 5, 81, 186, 187, 188, 48, 189, 113, 5, 190, 191, 23, 114, 192, 193, 12, 49, 82, 115, 27, 48, 194, 116, 117, 28, 195, 5, 196, 197, 14, 113, 7, 63, 50, 14, 39, 198, 5, 199, 4, 200, 15, 7, 83, 40, 201, 84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [202, 118, 203, 51, 204, 28, 205, 206, 52, 13, 29, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
